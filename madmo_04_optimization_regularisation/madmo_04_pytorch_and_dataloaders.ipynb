{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day 04: PyTorch warmup and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*special thanks to YSDA team for provided materials*\n",
    "Second part is based on PyTorch official tutorials and [this kaggle kernel](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comes today:\n",
    "- Introduction to PyTorch\n",
    "- Automatic gradient computation\n",
    "- Logistic regression (it's a neural network, actually ;) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://pytorch.org/tutorials/_static/pytorch-logo-dark.svg)\n",
    "\n",
    "__This notebook__ will teach you to use pytorch low-level core. You can install it [here](http://pytorch.org/).\n",
    "\n",
    "__Pytorch feels__ differently than other frameworks (like tensorflow/theano) on almost every level. TensorFlow makes your code live in two \"worlds\" simultaneously:  symbolic graphs and actual tensors. First you declare a symbolic \"recipe\" of how to get from inputs to outputs, then feed it with actual minibatches of data.  In pytorch, __there's only one world__: all tensors have a numeric value.\n",
    "\n",
    "You compute outputs on the fly without pre-declaring anything. The code looks exactly as in pure numpy with one exception: pytorch computes gradients for you. And can run stuff on GPU. And has a number of pre-implemented building blocks for your neural nets. [And a few more things.](https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)\n",
    "\n",
    "Let's dive into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:51:45.476855Z",
     "start_time": "2021-04-19T17:51:45.474765Z"
    }
   },
   "outputs": [],
   "source": [
    "# In Google Colab uncomment this\n",
    "\n",
    "# ! wget https://raw.githubusercontent.com/v-goncharenko/madmo-21-04/madmo_04_optimization_regularization/notmnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:51:46.164103Z",
     "start_time": "2021-04-19T17:51:45.794872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:51:46.856380Z",
     "start_time": "2021-04-19T17:51:46.175698Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warming up: Tensormancy\n",
    "\n",
    "**The [_disclaimer_](https://gist.githubusercontent.com/justheuristic/e2c1fa28ca02670cabc42cacf3902796/raw/fd3d935cef63a01b85ed2790b5c11c370245cbd7/stddisclaimer.h)**\n",
    "\n",
    "Let's write another function, this time in polar coordinates:\n",
    "$$\\rho(\\theta) = (1 + 0.9 \\cdot cos (6 \\cdot \\theta) ) \\cdot (1 + 0.01 \\cdot cos(24 \\cdot \\theta)) \\cdot (0.5 + 0.05 \\cdot cos(200 \\cdot \\theta)) \\cdot (10 + sin(10 \\cdot \\theta))$$\n",
    "\n",
    "\n",
    "Then convert it into cartesian coordinates ([howto](http://www.mathsisfun.com/polar-cartesian-coordinates.html)) and plot the results.\n",
    "\n",
    "Use torch tensors only: no lists, loops, numpy arrays, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.linspace(-np.pi, np.pi, steps=1000)\n",
    "\n",
    "# compute rho(theta) as per formula above\n",
    "rho = None\n",
    "\n",
    "# Now convert polar (rho, theta) pairs into cartesian (x,y) to plot them.\n",
    "x = None  # <your_code_here>\n",
    "y = None  # <your_code_here>\n",
    "\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "plt.fill(x.numpy(), y.numpy(), color=\"red\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The game of life\n",
    "\n",
    "Now it's time for you to make something more challenging. We'll implement Conway's [Game of Life](http://web.stanford.edu/~cdebs/GameOfLife/) in _pure pytorch_. \n",
    "\n",
    "While this is still a toy task, implementing game of life this way has one cool benefit: __you'll be able to run it on GPU! __ Indeed, what could be a better use of your gpu than simulating game of life on 1M/1M grids?\n",
    "\n",
    "![img](https://cdn.tutsplus.com/gamedev/authors/legacy/Stephane%20Beniak/2012/09/11/Preview_Image.png)\n",
    "If you've skipped the url above out of sloth, here's the game of life:\n",
    "* You have a 2D grid of cells, where each cell is \"alive\"(1) or \"dead\"(0)\n",
    "* Any living cell that has 2 or 3 neighbors survives, else it dies [0,1 or 4+ neighbors]\n",
    "* Any cell with exactly 3 neighbors becomes alive (if it was dead)\n",
    "\n",
    "For this task, you are given a reference numpy implementation that you must convert to pytorch.\n",
    "_[numpy code inspired by: https://github.com/rougier/numpy-100]_\n",
    "\n",
    "\n",
    "__Note:__ You can find convolution in `torch.nn.functional.conv2d(Z,filters)`. Note that it has a different input format.\n",
    "\n",
    "__Note 2:__ From the mathematical standpoint, pytorch convolution is actually cross-correlation. Those two are very similar operations. More info: [video tutorial](https://www.youtube.com/watch?v=C3EEy8adxvc), [scipy functions review](http://programmerz.ru/questions/26903/2d-convolution-in-python-similar-to-matlabs-conv2-question), [stack overflow source](https://stackoverflow.com/questions/31139977/comparing-matlabs-conv2-with-scipys-convolve2d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d\n",
    "\n",
    "\n",
    "def np_update(Z):\n",
    "    # Count neighbours with convolution\n",
    "    filters = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "\n",
    "    N = correlate2d(Z, filters, mode=\"same\")\n",
    "\n",
    "    # Apply rules\n",
    "    birth = (N == 3) & (Z == 0)\n",
    "    survive = ((N == 2) | (N == 3)) & (Z == 1)\n",
    "\n",
    "    Z[:] = birth | survive\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_update(Z):\n",
    "    \"\"\"\n",
    "    Implement an update function that does to Z exactly the same as np_update.\n",
    "    :param Z: torch.FloatTensor of shape [height,width] containing 0s(dead) an 1s(alive)\n",
    "    :returns: torch.FloatTensor Z after updates.\n",
    "\n",
    "    You can opt to create new tensor or change Z inplace.\n",
    "    \"\"\"\n",
    "\n",
    "    # <Your code here!>\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial frame\n",
    "Z_numpy = np.random.choice([0, 1], p=(0.5, 0.5), size=(100, 100))\n",
    "Z = torch.from_numpy(Z_numpy).type(torch.FloatTensor)\n",
    "\n",
    "# your debug polygon :)\n",
    "Z_new = torch_update(Z.clone())\n",
    "\n",
    "# tests\n",
    "Z_reference = np_update(Z_numpy.copy())\n",
    "assert np.all(\n",
    "    Z_new.numpy() == Z_reference\n",
    "), \"your pytorch implementation doesn't match np_update. Look into Z and np_update(ZZ) to investigate.\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "# initialize game field\n",
    "Z = np.random.choice([0, 1], size=(100, 100))\n",
    "Z = torch.from_numpy(Z).type(torch.FloatTensor)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    # update\n",
    "    Z = torch_update(Z)\n",
    "\n",
    "    # re-draw image\n",
    "    ax.clear()\n",
    "    ax.imshow(Z.numpy(), cmap=\"gray\")\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fun setups for your amusement\n",
    "\n",
    "# parallel stripes\n",
    "Z = np.arange(100) % 2 + np.zeros([100, 100])\n",
    "# with a small imperfection\n",
    "Z[48:52, 50] = 1\n",
    "\n",
    "Z = torch.from_numpy(Z).type(torch.FloatTensor)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "\n",
    "for _ in range(100):\n",
    "    Z = torch_update(Z)\n",
    "    ax.clear()\n",
    "    ax.imshow(Z.numpy(), cmap=\"gray\")\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More fun with Game of Life: [video](https://www.youtube.com/watch?v=C2vgICfQawE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Going serious with NotMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notmnist import load_notmnist\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_notmnist(letters=\"AB\", test_size=0)\n",
    "X_train, X_test = X_train.reshape([-1, 784]), X_test.reshape([-1, 784])\n",
    "\n",
    "print(\"Train size = %i, test_size = %i\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(X_train[i].reshape([28, 28]))\n",
    "    plt.title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with layers. The main abstraction here is __`torch.nn.Module`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network again just in case\n",
    "model = nn.Sequential()\n",
    "model.add_module(\"first\", nn.Linear(784, 1))\n",
    "model.add_module(\"second\", nn.Sigmoid())\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # sample 256 random images\n",
    "    ix = np.random.randint(0, len(X_train), 256)\n",
    "    x_batch = torch.tensor(X_train[ix], dtype=torch.float32)\n",
    "    y_batch = torch.tensor(y_train[ix], dtype=torch.float32)\n",
    "\n",
    "    # predict probabilities\n",
    "    y_predicted = None  ### YOUR CODE\n",
    "\n",
    "    assert y_predicted.dim() == 1, \"did you forget to select first column with [:, 0]\"\n",
    "\n",
    "    # compute loss, just like before\n",
    "    loss = None  ### YOUR CODE\n",
    "\n",
    "    # compute gradients\n",
    "    ### YOUR CODE\n",
    "\n",
    "    # Adam step\n",
    "    ### YOUR CODE\n",
    "\n",
    "    # clear gradients\n",
    "    ### YOUR CODE\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"step #%i | mean loss = %.3f\" % (i, np.mean(history[-10:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your model to predict classes (0 or 1) for all test samples\n",
    "predicted_y_test = None  ### YOUR CODE\n",
    "predicted_y_test = np.array(predicted_y_test > 0.5)\n",
    "\n",
    "assert isinstance(predicted_y_test, np.ndarray), \"please return np array, not %s\" % type(\n",
    "    predicted_y_test\n",
    ")\n",
    "assert predicted_y_test.shape == y_test.shape, \"please predict one class for each test sample\"\n",
    "assert np.in1d(predicted_y_test, y_test).all(), \"please predict class indexes\"\n",
    "\n",
    "accuracy = np.mean(predicted_y_test == y_test)\n",
    "\n",
    "print(\"Test accuracy: %.5f\" % accuracy)\n",
    "assert accuracy > 0.95, \"try training longer\"\n",
    "\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Using the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data, self.labels, _, _ = load_notmnist(path=file_path, test_size=0)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "        image = self.data[index].transpose(1, 2, 0)\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetMNIST(\"./notMNIST_small\", transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access and get data with index by __getitem__(index)\n",
    "img, lab = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(full_dataset[i][0].reshape([28, 28]))\n",
    "    plt.title(str(full_dataset[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dataloader as iterator by using iter() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at images and labels of batch size by extracting data `.next()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train_iter.next()\n",
    "\n",
    "print(\"images shape on batch size = {}\".format(images.size()))\n",
    "print(\"labels shape on batch size = {}\".format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make grid takes tensor as arg\n",
    "# tensor : (batchsize, channels, height, width)\n",
    "grid = torchvision.utils.make_grid(images.permute([0, 3, 1, 2]))\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis(\"off\")\n",
    "plt.title(labels.numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_with_transform = DatasetMNIST(\n",
    "    \"./notMNIST_small\", transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = train_dataset_with_transform.__getitem__(0)\n",
    "\n",
    "print(\"image shape at the first row : {}\".format(img.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader2 = DataLoader(train_dataset_with_transform, batch_size=8, shuffle=True)\n",
    "\n",
    "train_iter2 = iter(train_loader2)\n",
    "print(type(train_iter2))\n",
    "\n",
    "images, labels = train_iter2.next()\n",
    "\n",
    "print(\"images shape on batch size = {}\".format(images.size()))\n",
    "print(\"labels shape on batch size = {}\".format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis(\"off\")\n",
    "plt.title(labels.numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing several transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to take data augmentation, you have to make List using `torchvision.transforms.Compose`\n",
    "\n",
    "```\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "```\n",
    "\n",
    "\n",
    "this function can convert some image by order within `__call__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeToVector:\n",
    "    def __call__(self, pic):\n",
    "        return pic.view(pic.size(0), -1)[0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ReshapeToVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), ReshapeToVector()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_final = DatasetMNIST(\"./notMNIST_small\", transform=new_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset_final, batch_size=8, shuffle=True)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "\n",
    "print(\"images shape on batch size = {}\".format(images.size()))\n",
    "print(\"labels shape on batch size = {}\".format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network again just in case\n",
    "model = nn.Sequential()\n",
    "model.add_module(\"first\", nn.Linear(784, 10))\n",
    "model.add_module(\"second\", nn.Softmax())\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for i in range(100):\n",
    "    # sample 256 random images\n",
    "    x_batch, y_batch = train_iter.next()\n",
    "\n",
    "    # predict probabilities\n",
    "    y_predicted = model(x_batch)\n",
    "\n",
    "    # assert y_predicted.dim() == 1, \"did you forget to select first column with [:, 0]\"\n",
    "\n",
    "    # compute loss, just like before\n",
    "    loss = F.cross_entropy(y_predicted, y_batch, reduction=\"mean\")  ### YOUR CODE\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    ### YOUR CODE\n",
    "\n",
    "    # Adam step\n",
    "    opt.step()\n",
    "    ### YOUR CODE\n",
    "\n",
    "    # clear gradients\n",
    "    opt.zero_grad()\n",
    "    ### YOUR CODE\n",
    "\n",
    "    history.append(loss.data.numpy())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"step #%i | mean loss = %.3f\" % (i, np.mean(history[-10:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "Try to add some additional transformations (e.g. random crop, rotation etc.) and train your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More about pytorch\n",
    "\n",
    "* Using torch on GPU and multi-GPU - [link](http://pytorch.org/docs/master/notes/cuda.html)\n",
    "* More tutorials on pytorch - [link](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* Pytorch examples - a repo that implements many cool DL models in pytorch - [link](https://github.com/pytorch/examples)\n",
    "* Practical pytorch - a repo that implements some... other cool DL models... yes, in pytorch - [link](https://github.com/spro/practical-pytorch)\n",
    "* And some more - [link](https://www.reddit.com/r/pytorch/comments/6z0yeo/pytorch_and_pytorch_tricks_for_kaggle/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-mipt]",
   "language": "python",
   "name": "conda-env-ml-mipt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
